{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "This script aims at creating a training and a testing set from the iPinYou data contest\n",
    "\n",
    "This script is composed of 4 parts \n",
    "1. Import librairies and change directory to where the data lies \n",
    "    ACTION REQUIRED: you need to update the path to your folder \n",
    "\n",
    "2. Define parameters \n",
    "\n",
    "3. Define function for extracting day of the data and sampling it \n",
    "\n",
    "4. Script to build full dataset \n",
    "ACTION REQUIRED: \n",
    "- Update random state in parameters  \n",
    "- Update n_sampling \n",
    "\n",
    "\n",
    "Author: Armand Sauzay\n",
    "Email: armand.sauzay@berkeley.edu\n",
    "\"\"\"\n",
    "# 1. Import librairies\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change directory to where the data lies (training2nd --> 2nd session of contest)\n",
    "os.chdir('C:/Users/vishn/Documents/ipinyou.contest.dataset - unzipped/ipinyou.contest.dataset/training2nd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define Parameters\n",
    "header_season2_bids=[\n",
    "    'Bid ID'\n",
    "    ,'Timestamp'\n",
    "    ,'iPinYou ID'\n",
    "    ,'User-Agent'\n",
    "    ,'IP'\n",
    "    ,'Region ID'\n",
    "    ,'City ID'\n",
    "    ,'Ad Exchange'\n",
    "    ,'Domain'\n",
    "    ,'URL'\n",
    "    ,'Anonymous URL'\n",
    "    ,'Ad Slot ID'\n",
    "    ,'Ad Slot Width'\n",
    "    ,'Ad Slot Height'\n",
    "    ,'Ad Slot Visibility'\n",
    "    ,'Ad Slot Format'\n",
    "    ,'Ad Slot Floor Price'\n",
    "    ,'Creative ID'\n",
    "    ,'Bidding Price'\n",
    "    ,'Advertiser ID'\n",
    "    ,'User Profile IDs']\n",
    "\n",
    "header_season2=[\n",
    "    'Bid ID'\n",
    "    ,'Timestamp'\n",
    "    ,'Log Type'\n",
    "    ,'iPinYou ID'\n",
    "    ,'User-Agent'\n",
    "    ,'IP'\n",
    "    ,'Region ID'\n",
    "    ,'City ID'\n",
    "    ,'Ad Exchange'\n",
    "    ,'Domain'\n",
    "    ,'URL'\n",
    "    ,'Anonymous URL'\n",
    "    ,'Ad Slot ID'\n",
    "    ,'Ad Slot Width'\n",
    "    ,'Ad Slot Height'\n",
    "    ,'Ad Slot Visibility'\n",
    "    ,'Ad Slot Format'\n",
    "    ,'Ad Slot Floor Price'\n",
    "    ,'Creative ID'\n",
    "    ,'Bidding Price'\n",
    "    ,'Paying Price'\n",
    "    ,'Landing Page URL'\n",
    "    ,'Advertiser ID'\n",
    "    ,'User Profile IDs']\n",
    "\n",
    "dates_list=['20130606'\n",
    "           , '20130607'\n",
    "           , '20130608'\n",
    "           , '20130609'\n",
    "           , '20130610'\n",
    "           , '20130611'\n",
    "           , '20130612']\n",
    "\n",
    "random_state=100\n",
    "frac_to_take=0.01\n",
    "n_sampling=100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. one day data\n",
    "def one_day_training_testing(date):\n",
    "    # READ DATA FOR 1 DAY \n",
    "    print('reading data for %s'%date)\n",
    "    unzipped_file = bz2.BZ2File('bid.'+date+'.txt.bz2', \"r\")\n",
    "    bids=pd.read_table(unzipped_file, names=header_season2_bids, low_memory= False)\n",
    "\n",
    "    unzipped_file = bz2.BZ2File('imp.'+date+'.txt.bz2', \"r\")\n",
    "    impressions=pd.read_table(unzipped_file, names=header_season2, low_memory= False)\n",
    "    \n",
    "    unzipped_file = bz2.BZ2File('clk.'+date+'.txt.bz2', \"r\")\n",
    "    clicks=pd.read_table(unzipped_file, names=header_season2, low_memory= False)\n",
    "    \n",
    "    unzipped_file = bz2.BZ2File('conv.'+date+'.txt.bz2', \"r\")\n",
    "    conversions=pd.read_table(unzipped_file, names=header_season2, low_memory= False)\n",
    "    conversions=pd.read_table(unzipped_file, names=header_season2)\n",
    "\n",
    "    all_data={'bids': bids, 'impressions':impressions, 'clicks':clicks, 'conversions':conversions}\n",
    "    for key, value in all_data.items(): \n",
    "        print('shape of %s is %s'%(key, value.shape))\n",
    "\n",
    "    #ASSUMPTION 1: SOME COLUMNS CAN BE DROPPED BECAUSE THEY HAVE NO PREDICTIVE POWER\n",
    "    cols_to_drop=['iPinYou ID'\n",
    "                ,'IP'\n",
    "                ,'Domain'\n",
    "                ,'URL'\n",
    "                ,'Anonymous URL'\n",
    "                ,'Ad Slot ID'\n",
    "                ,'Creative ID']\n",
    "\n",
    "    for index, value in all_data.items(): \n",
    "        value.drop(cols_to_drop, axis=1, inplace =True)\n",
    "        if index!='bids': \n",
    "            value.drop('Landing Page URL', axis=1, inplace=True)\n",
    "\n",
    "# IMPRESSION MERGE \n",
    "    ## ASSUMPTION 2.1:COUNT DUPLICATES ON BID ID FOR IMPRESSIONS AND ADD THEM TO LINE\n",
    "    ## ASSUMPTION 2.2: ONLY KEEP COLUMNS THAT ACTUALLY DIFFER IN THE IMPRESSION TABLE\n",
    "    impression_count=impressions.groupby(['Bid ID']).size()\n",
    "    impression_to_merge =pd.merge(impressions[['Bid ID'\n",
    "            , 'Timestamp'\n",
    "            , 'User-Agent'\n",
    "            , 'Log Type'\n",
    "            , 'Paying Price'\n",
    "            , 'User Profile IDs']].drop_duplicates('Bid ID'), impression_count.rename('n_impressions'), left_on='Bid ID',right_index=True)\n",
    "    df=pd.merge(bids, impression_to_merge, on=\"Bid ID\", suffixes=('_bid', '_imp'), how=\"left\")\n",
    "    \n",
    "#CLICKS MERGE\n",
    "    ## ASSUMPTION 3.1: COUNT DUPLICATES FOR BID ID FOR CLICKS AND ADD THEM  \n",
    "    ## ASSUMPTION 3.2: ONLY KEEP COLUMNS THAT ACTUALLY DIFFER IN THE CLICKS TABLE\n",
    "    clicks_count=clicks.groupby(['Bid ID']).size()\n",
    "    clicks_to_merge =pd.merge(clicks[['Bid ID'\n",
    "                        , 'Timestamp'\n",
    "                        , 'User-Agent'\n",
    "                        , 'User Profile IDs'\n",
    "                        , 'Region ID'\n",
    "                        ]].drop_duplicates('Bid ID'), clicks_count.rename('n_clicks'), left_on='Bid ID',right_index=True)     \n",
    "    df=pd.merge(df, clicks_to_merge, left_on=\"Bid ID\",right_on=\"Bid ID\", suffixes=('_bids_join_impressions', '_clicks'), how=\"left\")\n",
    "\n",
    "    # ADD COLUMNS (QUITE REDUNDANT WITH n_clicks & n_impressions)\n",
    "    df['has impression']=~(df['Timestamp_imp'].isna())\n",
    "    df['has click']=~(df['Region ID_clicks'].isna())\n",
    "    #CONVERT BOOL TO INT \n",
    "    df['has impression']=df['has impression'].astype(int)\n",
    "    df['has click']=df['has click'].astype(int)\n",
    "\n",
    "    #REDUCE SIZE   \n",
    "    cols_to_drop = ['Bid ID']\n",
    "    df.drop(cols_to_drop, axis=1, inplace =True)\n",
    "\n",
    "    #SAMPLE THE DATASET\n",
    "    #df=df.sample(n=n_sampling, ,random_state=random_state)\n",
    "    train, test = train_test_split(df, test_size=frac_to_take, random_state= random_state, stratify=df[['has click','has impression']])\n",
    "    \n",
    "    \n",
    "    return(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data for 20130606\n",
      "shape of bids is (9586949, 21)\n",
      "shape of impressions is (1821350, 24)\n",
      "shape of clicks is (1289, 24)\n",
      "shape of conversions is (0, 24)\n"
     ]
    }
   ],
   "source": [
    "df_final=one_day_training_testing('20130606')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data for 20130607\n",
      "shape of bids is (11132555, 21)\n",
      "shape of impressions is (1805953, 24)\n",
      "shape of clicks is (1158, 24)\n",
      "shape of conversions is (0, 24)\n"
     ]
    }
   ],
   "source": [
    "for date in dates_list[1:]:    \n",
    "    df=one_day_training_testing(date)\n",
    "    print('shape of df is %s'%str(df.shape))\n",
    "    df_final=df_final.append(df)\n",
    "    print('shape of df_final is %s'%str(df_final.shape))\n",
    "\n",
    "#take mapping for user profile\n",
    "#mapping=pd.read_table('/Users/Armand/Capstone/ipinyou.contest.dataset/user.profile.tags.en.txt', names=('key','value'))\n",
    "\n",
    "#dummify user profile\n",
    "s=df_final['User Profile IDs_imp'].str.split(pat=',')\n",
    "dummies_to_concatenate=pd.get_dummies(s.apply(pd.Series).stack()).sum(level=0)\n",
    "\n",
    "df_dummified = df_final.merge(dummies_to_concatenate, left_index=True, right_index=True, how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummified.to_csv('final_training_testing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# Total bid is \",len(df_dummified['has click']))\n",
    "print(\"# Impressions is \", sum(df_dummified['has impression']))\n",
    "print(\"# Clicks is \", sum(df_dummified['has click']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
