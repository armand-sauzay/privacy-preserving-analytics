{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('test': conda)",
   "metadata": {
    "interpreter": {
     "hash": "94e314bcb2e2c94098a96ce8345f3056e80c3e177e83b5f756ccedf62ae30c5b"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.8.0-py3-none-any.whl (206 kB)\n",
      "\u001b[K     |████████████████████████████████| 206 kB 229 kB/s \n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24 in /Users/Armand/anaconda3/envs/test/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (0.24.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/Armand/anaconda3/envs/test/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.20.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/Armand/anaconda3/envs/test/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Users/Armand/anaconda3/envs/test/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.6.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/Armand/anaconda3/envs/test/lib/python3.9/site-packages (from scikit-learn>=0.24->imbalanced-learn->imblearn) (2.1.0)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.8.0 imblearn-0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import bz2\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import make_csv_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "reading data for 20130606\n",
      "shape of impressions is (1821350, 24)\n",
      "shape of clicks is (1289, 24)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'RandomUnderSampler' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5097ada1c548>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmake_csv_imp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_day_training_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'20130606'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Capstone/privacy-preserving-analytics/final/0.dataset/make_csv_imp.py\u001b[0m in \u001b[0;36mone_day_training_testing\u001b[0;34m(date, random_state, frac_to_take, n_sampling)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mn_0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0mrus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomUnderSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m     \u001b[0mX_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Resampled dataset shape %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RandomUnderSampler' is not defined"
     ]
    }
   ],
   "source": [
    "make_csv_imp.one_day_training_testing('20130606')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=10000, weights=[0.99], flip_y=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({0: 9900, 1: 100})"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original dataset shape Counter({1: 900, 0: 100})\nResampled dataset shape Counter({1: 900, 0: 100})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "\n",
    "X, y = make_classification(n_classes=2, class_sep=2, weights=[0.1, 0.9], n_informative=3, n_redundant=1, flip_y=0,\n",
    "n_features=20, n_clusters_per_class=1, n_samples=1000, random_state=10)\n",
    "\n",
    "print('Original dataset shape %s' % Counter(y))\n",
    "rus = RandomUnderSampler(sampling_strategy={1:900, 0:100})\n",
    "X_res, y_res = rus.fit_resample(X, y)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1821350, 21)"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_final.drop(['has click'], axis=1)\n",
    "y=df_final['has click']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Timestamp_impressions             int64\n",
       "Log Type                          int64\n",
       "User-Agent_impressions           object\n",
       "Region ID_impressions             int64\n",
       "City ID                           int64\n",
       "Ad Exchange                       int64\n",
       "Ad Slot Width                     int64\n",
       "Ad Slot Height                    int64\n",
       "Ad Slot Visibility                int64\n",
       "Ad Slot Format                    int64\n",
       "Ad Slot Floor Price               int64\n",
       "Bidding Price                     int64\n",
       "Paying Price                      int64\n",
       "Advertiser ID                     int64\n",
       "User Profile IDs_impressions     object\n",
       "Timestamp_clicks                float64\n",
       "User-Agent_clicks                object\n",
       "User Profile IDs_clicks          object\n",
       "Region ID_clicks                float64\n",
       "n_clicks                        float64\n",
       "has click                         int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "source": [
    "df_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Resampled dataset shape Counter({0: 18213, 1: 1161})\n"
     ]
    }
   ],
   "source": [
    "n_1=df_final['has click'].sum()\n",
    "n_0=int(0.01*len(df_final))\n",
    "\n",
    "rus = RandomUnderSampler(sampling_strategy={1:n_1, 0:n_0})\n",
    "X_res, y_res = rus.fit_resample(X, y)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    18201.89\n",
       "1       11.61\n",
       "Name: has click, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 110
    }
   ],
   "source": [
    "df_final['has click'].value_counts()/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "reading data for 20130606\n",
      "shape of impressions is (1821350, 24)\n",
      "shape of clicks is (1289, 24)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "This script aims at creating a training and a testing set from the iPinYou data contest\n",
    "\n",
    "This script is composed of 4 parts \n",
    "1. Import librairies and change directory to where the data lies \n",
    "    ACTION REQUIRED: you need to update the path to your folder \n",
    "\n",
    "2. Define parameters \n",
    "\n",
    "3. Define function for extracting day of the data and sampling it \n",
    "\n",
    "4. Script to build full dataset \n",
    "ACTION REQUIRED: \n",
    "- Update random state in parameters  \n",
    "- Update n_sampling \n",
    "\n",
    "\n",
    "Author: Armand Sauzay\n",
    "Email: armand.sauzay@berkeley.edu\n",
    "\"\"\"\n",
    "# 1. Import librairies\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import bz2\n",
    "\n",
    "#Change directory to where the data lies (training2nd --> 2nd session of contest)\n",
    "os.chdir('/Users/Armand/Capstone/ipinyou.contest.dataset/training2nd')\n",
    "\n",
    "# 2. Define Parameters\n",
    "header_season2=[\n",
    "    'Bid ID'\n",
    "    ,'Timestamp'\n",
    "    ,'Log Type'\n",
    "    ,'iPinYou ID'\n",
    "    ,'User-Agent'\n",
    "    ,'IP'\n",
    "    ,'Region ID'\n",
    "    ,'City ID'\n",
    "    ,'Ad Exchange'\n",
    "    ,'Domain'\n",
    "    ,'URL'\n",
    "    ,'Anonymous URL'\n",
    "    ,'Ad Slot ID'\n",
    "    ,'Ad Slot Width'\n",
    "    ,'Ad Slot Height'\n",
    "    ,'Ad Slot Visibility'\n",
    "    ,'Ad Slot Format'\n",
    "    ,'Ad Slot Floor Price'\n",
    "    ,'Creative ID'\n",
    "    ,'Bidding Price'\n",
    "    ,'Paying Price'\n",
    "    ,'Landing Page URL'\n",
    "    ,'Advertiser ID'\n",
    "    ,'User Profile IDs']\n",
    "\n",
    "dates_list=['20130606'\n",
    "           , '20130607'\n",
    "           , '20130608'\n",
    "           , '20130609'\n",
    "           , '20130610'\n",
    "           , '20130611'\n",
    "           , '20130612']\n",
    "\n",
    "random_state=100\n",
    "frac_to_take=0.01\n",
    "n_sampling=100000\n",
    "\n",
    "\n",
    "#3. one day data\n",
    "def one_day_training_testing(date):\n",
    "    # READ DATA FOR 1 DAY \n",
    "    print('reading data for %s'%date)\n",
    "    #unzipped_file = bz2.BZ2File('bid.'+date+'.txt.bz2', \"r\")\n",
    "    #bids=pd.read_table(unzipped_file, names=header_season2_bids)\n",
    "\n",
    "    unzipped_file = bz2.BZ2File('imp.'+date+'.txt.bz2', \"r\")\n",
    "    impressions=pd.read_table(unzipped_file, names=header_season2)\n",
    "    \n",
    "    unzipped_file = bz2.BZ2File('clk.'+date+'.txt.bz2', \"r\")\n",
    "    clicks=pd.read_table(unzipped_file, names=header_season2)\n",
    "    \n",
    "    #unzipped_file = bz2.BZ2File('conv.'+date+'.txt.bz2', \"r\")\n",
    "    #conversions=pd.read_table(unzipped_file, names=header_season2)\n",
    "\n",
    "    all_data={'impressions':impressions, 'clicks':clicks}\n",
    "    for key, value in all_data.items(): \n",
    "        print('shape of %s is %s'%(key, value.shape))\n",
    "\n",
    "    #ASSUMPTION 1: SOME COLUMNS CAN BE DROPPED BECAUSE THEY HAVE NO PREDICTIVE POWER\n",
    "    cols_to_drop=['iPinYou ID'\n",
    "                ,'IP'\n",
    "                ,'Domain'\n",
    "                ,'URL'\n",
    "                ,'Anonymous URL'\n",
    "                ,'Ad Slot ID'\n",
    "                ,'Creative ID']\n",
    "\n",
    "    for index, value in all_data.items(): \n",
    "        value.drop(cols_to_drop, axis=1, inplace =True)\n",
    "        if index!='bids': \n",
    "            value.drop('Landing Page URL', axis=1, inplace=True)\n",
    "\n",
    "# IMPRESSION MERGE \n",
    "    ## ASSUMPTION 2.1:COUNT DUPLICATES ON BID ID FOR IMPRESSIONS AND ADD THEM TO LINE\n",
    "    ## ASSUMPTION 2.2: ONLY KEEP COLUMNS THAT ACTUALLY DIFFER IN THE IMPRESSION TABLE\n",
    "    \n",
    "    '''impression_count=impressions.groupby(['Bid ID']).size()\n",
    "    #impression_to_merge =pd.merge(impressions[['Bid ID'\n",
    "            , 'Timestamp'\n",
    "            , 'User-Agent'\n",
    "            , 'Log Type'\n",
    "            , 'Paying Price'\n",
    "            , 'User Profile IDs']].drop_duplicates('Bid ID'), impression_count.rename('n_impressions'), left_on='Bid ID',right_index=True)\n",
    "    #df=pd.merge(bids, impression_to_merge, on=\"Bid ID\", suffixes=('_bid', '_imp'), how=\"left\")'''\n",
    "\n",
    "#CLICKS MERGE\n",
    "    ## ASSUMPTION 3.1: COUNT DUPLICATES FOR BID ID FOR CLICKS AND ADD THEM  \n",
    "    ## ASSUMPTION 3.2: ONLY KEEP COLUMNS THAT ACTUALLY DIFFER IN THE CLICKS TABLE\n",
    "    clicks_count=clicks.groupby(['Bid ID']).size()\n",
    "    clicks_to_merge =pd.merge(clicks[['Bid ID'\n",
    "                        , 'Timestamp'\n",
    "                        , 'User-Agent'\n",
    "                        , 'User Profile IDs'\n",
    "                        , 'Region ID'\n",
    "                        ]].drop_duplicates('Bid ID'), clicks_count.rename('n_clicks'), left_on='Bid ID',right_index=True)     \n",
    "    df=pd.merge(impressions, clicks_to_merge, left_on=\"Bid ID\",right_on=\"Bid ID\", suffixes=('_impressions', '_clicks'), how=\"left\")\n",
    "\n",
    "    # ADD COLUMNS (QUITE REDUNDANT WITH n_clicks & n_impressions)\n",
    "    #df['has impression']=~(df['Timestamp_imp'].isna())\n",
    "    df['has click']=~(df['Region ID_clicks'].isna())\n",
    "    #CONVERT BOOL TO INT \n",
    "    #df['has impression']=df['has impression'].astype(int)\n",
    "    df['has click']=df['has click'].astype(int)\n",
    "\n",
    "    #REDUCE SIZE   \n",
    "    cols_to_drop = ['Bid ID']\n",
    "    df.drop(cols_to_drop, axis=1, inplace =True)\n",
    "\n",
    "    #SAMPLE THE DATASET\n",
    "    #df=df.sample(n=n_sampling, random_state=random_state)\n",
    "    return(df)\n",
    "\n",
    "df_final=one_day_training_testing('20130606')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date in dates_list[1:]:    \n",
    "    df=one_day_training_testing(date)\n",
    "    print('shape of df is %s'%str(df.shape))\n",
    "    df_final=df_final.append(df)\n",
    "    print('shape of df_final is %s'%str(df_final.shape))\n",
    "\n",
    "#take mapping for user profile\n",
    "#mapping=pd.read_table('/Users/Armand/Capstone/ipinyou.contest.dataset/user.profile.tags.en.txt', names=('key','value'))\n",
    "\n",
    "#dummify user profile\n",
    "s=df_final['User Profile IDs_imp'].str.split(pat=',')\n",
    "dummies_to_concatenate=pd.get_dummies(s.apply(pd.Series).stack()).sum(level=0)\n",
    "\n",
    "df_dummified = df_final.merge(dummies_to_concatenate, left_index=True, right_index=True, how='left')\n",
    "\n",
    "df_dummified.to_csv('/Users/Armand/Capstone/final_training_testing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}